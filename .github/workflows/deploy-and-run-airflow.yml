name: Deploy and Run Airflow DAG

on:
  workflow_dispatch:
  pull_request:
    types:
      - opened
      - synchronize
      - reopened

jobs:
  deploy-and-run:
    runs-on: ubuntu-latest

    steps:
    # 1. Checkout le code
    - name: Checkout repository
      uses: actions/checkout@v3

    # 2. Installer Docker Compose
    - name: Install Docker Compose
      run: |
        sudo apt-get update
        sudo apt-get install -y docker-compose

    - name: Changing permissions on volumes
      run: |
        sudo chmod -R 777 airflow/logs/
        sudo chmod -R 777 airflow/dags/
        sudo chmod -R 777 airflow/plugins/

    # 3. Construire et démarrer les services avec Docker Compose
    - name: Start Docker Compose Services
      run: |
        docker-compose -f docker-compose.yml up -d

    - name: Check Docker Compose Status
      run: |
        docker-compose -f docker-compose.yml ps
        docker-compose -f docker-compose.yml logs airflow-webserver

    - name: Inspect Docker Network
      run: |
        docker network ls
        docker network inspect bridge

    - name: Check permissions on volumes
      run: |
        ls -la airflow

    # 4. Attendre que les services soient prêts
    - name: Wait for Airflow Webserver
      run: |
        for i in {1..10}; do
          echo "Attempt $i: Checking if Airflow Webserver is ready..."
          if curl --fail http://localhost:8080/health; then
            echo "Airflow Webserver is ready."
            exit 0
          fi
          echo "Waiting for Airflow Webserver to be ready..."
          sleep 10
        done
        echo "Airflow Webserver did not start within the expected time."
        exit 1

    # 5. Déclencher le DAG Airflow
    - name: Trigger Airflow DAG
      id: trigger_dag
      run: |
        export AIRFLOW_USERNAME=airflow
        export AIRFLOW_PASSWORD=airflow
        DAG_RUN_ID=$(curl -s -X POST http://localhost:8080/api/v1/dags/ml_pipeline/dagRuns \
          -H "Content-Type: application/json" \
          -u "$AIRFLOW_USERNAME:$AIRFLOW_PASSWORD" \
          -d '{"conf": {}}' | jq -r '.dag_run_id')
        echo "Triggered DAG Run ID: $DAG_RUN_ID"
        echo "dag_run_id=$DAG_RUN_ID" >> $GITHUB_ENV

    # Attendre que le DAG soit terminé
    - name: Wait for Airflow DAG Completion
      run: |
        export AIRFLOW_USERNAME=airflow
        export AIRFLOW_PASSWORD=airflow
        for i in {1..30}; do
          STATE=$(curl -s -u "$AIRFLOW_USERNAME:$AIRFLOW_PASSWORD" \
            http://localhost:8080/api/v1/dags/ml_pipeline/dagRuns/$DAG_RUN_ID \
            | jq -r '.state')
          echo "Current state: $STATE"
          if [ "$STATE" == "success" ]; then
            echo "DAG execution succeeded."
            exit 0
          elif [ "$STATE" == "failed" ]; then
            echo "DAG execution failed."
            exit 1
          fi
          sleep 10
        done
        echo "DAG did not complete within the expected time."
        exit 1

    # Récupérer les logs des tâches du DAG
    - name: Fetch Airflow Task Logs
      run: |
        export AIRFLOW_USERNAME=airflow
        export AIRFLOW_PASSWORD=airflow
        export DAG_RUN_ID=$DAG_RUN_ID
        export DAG_ID=ml_pipeline

        # Initialisation des variables
        COMPLETED_TASKS=""
        TASKS_FAILED=0

        # Récupérer la liste des tâches
        TASKS=$(curl -s -u "$AIRFLOW_USERNAME:$AIRFLOW_PASSWORD" \
          http://localhost:8080/api/v1/dags/$DAG_ID/dagRuns/$DAG_RUN_ID/taskInstances \
          | jq -r '.task_instances[].task_id')

        # Boucle pour récupérer et afficher les logs
        for TASK_ID in $TASKS; do
          echo "Fetching logs for Task: $TASK_ID"
          # Récupérer l'état de la tâche
          TASK_STATE=$(curl -s -u "$AIRFLOW_USERNAME:$AIRFLOW_PASSWORD" \
            http://localhost:8080/api/v1/dags/$DAG_ID/dagRuns/$DAG_RUN_ID/taskInstances/$TASK_ID \
            | jq -r '.state')
          echo "State of Task $TASK_ID: $TASK_STATE"

          # Récupérer les logs
          LOGS=$(curl -s -u "$AIRFLOW_USERNAME:$AIRFLOW_PASSWORD" \
            http://localhost:8080/api/v1/dags/$DAG_ID/dagRuns/$DAG_RUN_ID/taskInstances/$TASK_ID/logs)
          echo "Logs for Task $TASK_ID:"
          echo "$LOGS"
          echo -e "\n---------------------------------------------\n"

          # Vérifier si la tâche a échoué
          if [ "$TASK_STATE" == "failed" ]; then
            echo "⚠️ Task $TASK_ID has failed. Check the logs above for details."
            TASKS_FAILED=$((TASKS_FAILED + 1))
          fi
        done

        # Vérifier si une ou plusieurs tâches ont échoué
        if [ "$TASKS_FAILED" -gt 0 ]; then
          echo "⚠️ $TASKS_FAILED task(s) have failed. Please check the logs for details."
          exit 1
        fi
  
    # 6. Afficher les logs des conteneurs en cas de succès ou d'échec
    - name: Show Docker Compose Logs
      if: always()
      run: docker-compose -f docker-compose.yml logs