name: Deploy and Run Airflow DAG

on:
  workflow_dispatch:
  pull_request:
    types:
      - opened
      - synchronize
      - reopened

jobs:
  deploy-and-run:
    runs-on: ubuntu-latest

    steps:
    # 1. Checkout le code
    - name: Checkout repository
      uses: actions/checkout@v3

    # 2. Installer Docker Compose
    - name: Install Docker Compose
      run: |
        sudo apt-get update
        sudo apt-get install -y docker-compose

    # 3. Construire et démarrer les services avec Docker Compose
    - name: Start Docker Compose Services
      run: |
        docker-compose -f docker-compose.yml up -d

    - name: Check Docker Compose Status
      run: |
        docker-compose -f docker-compose.yml ps
        docker-compose -f docker-compose.yml logs airflow-webserver

    - name: Inspect Docker Network
      run: |
        docker network ls
        docker network inspect bridge

    # 4. Attendre que les services soient prêts
    - name: Wait for Airflow Webserver
      run: |
        for i in {1..30}; do
          echo "Attempt $i: Checking if Airflow Webserver is ready..."
          curl -v http://airflow-webserver:8080/health || echo "Connection failed."
          if curl --fail http://airflow-webserver:8080/health; then
            echo "Airflow Webserver is ready."
            exit 0
          fi
          sleep 10
        done
        echo "Airflow Webserver did not start within the expected time."
        exit 1

    # 5. Déclencher le DAG Airflow
    - name: Trigger Airflow DAG
      run: |
        export AIRFLOW_USERNAME=airflow
        export AIRFLOW_PASSWORD=airflow
        curl -X POST http://localhost:8080/api/v1/dags/ml_pipeline/dagRuns \
          -H "Content-Type: application/json" \
          -u "$AIRFLOW_USERNAME:$AIRFLOW_PASSWORD" \
          -d '{"conf": {}}'

    # 6. Afficher les logs des conteneurs en cas de succès ou d'échec
    - name: Show Docker Compose Logs
      if: always()
      run: docker-compose -f docker-compose.yml logs